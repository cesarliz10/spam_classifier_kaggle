{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('spam.csv')\n",
    "df['target'] = np.where(df['target']=='spam',1,0)\n",
    "df['msg_len']  = df['text'].str.len()\n",
    "df['non_word_char'] = df[\"text\"].str.count(r'\\W')\n",
    "df['num_char'] = df[\"text\"].str.count(r'\\d')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['text','msg_len','non_word_char','num_char']],df['target'], random_state=0,train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of different Tokenizing strategies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the previous text data analyis discussion, let's compare the performance of the `CountVectorizer`and `TfidfVectorizer` vectorizers using the following classifier algorithms:  \n",
    "[Multinomial Naive Classiffier](https://scikit-learn.org/stable/modules/naive_bayes.html)    \n",
    "[Support Vector classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)  \n",
    "[Logistic Classifier](https://scikitlearn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "We use the *AUC score* as evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "c1 = MultinomialNB(alpha=0.1)\n",
    "c2 = SVC(kernel='linear')\n",
    "c3 = LogisticRegression(C=10,solver='lbfgs')\n",
    "\n",
    "model = dict([(\"Bayes\",c1),(\"SVC\",c2),(\"Logit\",c3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that tokenizing with default parameters led to a vocabulary length of about ~7k, but the *document frecuency* of most of these tokens is 1, meaning that they appear only in one training example. A set of features much larger than the number of training examples is prone to  overfit. \n",
    "\n",
    "Let's impose a Change the *minimum document frecuency* of the vectorizers  and check the training and test performance of the previously defined classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer_performance(v1,v2,classif):\n",
    "    auc_train = []\n",
    "    auc_test  = []\n",
    "    for vectorizer in [v1,v2]:\n",
    "        X_train_transf = vectorizer.transform(X_train[\"text\"])\n",
    "        clf = model[classif].fit(X_train_transf,y_train)\n",
    "        y_pred_train = clf.predict(X_train_transf)\n",
    "        auc_train.append(roc_auc_score(y_train,y_pred_train) )\n",
    "        y_pred = clf.predict(vectorizer.transform(X_test[\"text\"]))\n",
    "        auc_test.append(roc_auc_score(y_test,y_pred) )\n",
    "    print(\"*** AUC scores for {} Classifier ***\".format(classif))\n",
    "    print(\"Train: {:0.2f} , {:0.2f}\".format(auc_train[0],auc_train[1]))\n",
    "    print(\"Test: {:0.2f} , {:0.2f}\".format(auc_test[0],auc_test[1]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Vocabulary length for min_df=1 -->  7098 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.99 , 0.99\n",
      "Test: 0.98 , 0.94\n",
      "CPU times: user 187 ms, sys: 0 ns, total: 187 ms\n",
      "Wall time: 187 ms\n",
      "*** AUC scores for SVC Classifier ***\n",
      "Train: 1.00 , 0.98\n",
      "Test: 0.94 , 0.96\n",
      "CPU times: user 1.96 s, sys: 9.18 ms, total: 1.97 s\n",
      "Wall time: 1.97 s\n",
      "*** AUC scores for Logit Classifier ***\n",
      "Train: 1.00 , 0.99\n",
      "Test: 0.93 , 0.95\n",
      "CPU times: user 352 ms, sys: 247 µs, total: 353 ms\n",
      "Wall time: 352 ms\n",
      "######### Vocabulary length for min_df=3 -->  2199 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.98 , 0.97\n",
      "Test: 0.97 , 0.94\n",
      "CPU times: user 194 ms, sys: 394 µs, total: 194 ms\n",
      "Wall time: 194 ms\n",
      "*** AUC scores for SVC Classifier ***\n",
      "Train: 1.00 , 0.97\n",
      "Test: 0.95 , 0.96\n",
      "CPU times: user 1.46 s, sys: 4.19 ms, total: 1.46 s\n",
      "Wall time: 1.46 s\n",
      "*** AUC scores for Logit Classifier ***\n",
      "Train: 1.00 , 0.98\n",
      "Test: 0.95 , 0.96\n",
      "CPU times: user 338 ms, sys: 0 ns, total: 338 ms\n",
      "Wall time: 337 ms\n",
      "######### Vocabulary length for min_df=6 -->  1212 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.97 , 0.96\n",
      "Test: 0.97 , 0.95\n",
      "CPU times: user 191 ms, sys: 0 ns, total: 191 ms\n",
      "Wall time: 191 ms\n",
      "*** AUC scores for SVC Classifier ***\n",
      "Train: 1.00 , 0.97\n",
      "Test: 0.96 , 0.96\n",
      "CPU times: user 1.18 s, sys: 8.1 ms, total: 1.19 s\n",
      "Wall time: 1.19 s\n",
      "*** AUC scores for Logit Classifier ***\n",
      "Train: 1.00 , 0.98\n",
      "Test: 0.95 , 0.96\n",
      "CPU times: user 293 ms, sys: 133 µs, total: 293 ms\n",
      "Wall time: 292 ms\n"
     ]
    }
   ],
   "source": [
    "for i in [1,3,6]:\n",
    "    v1 = CountVectorizer(min_df=i).fit(X_train[\"text\"])\n",
    "    v2 = TfidfVectorizer(min_df=i).fit(X_train[\"text\"])\n",
    "    print(\"######### Vocabulary length for min_df={} -->  {} #########\".format(i, len(v1.vocabulary_)))\n",
    "    %time vectorizer_performance(v1,v2,\"Bayes\")\n",
    "    %time vectorizer_performance(v1,v2,\"SVC\")\n",
    "    %time vectorizer_performance(v1,v2,\"Logit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both vectorizers have rather similar performances (Test AUC scores), somehow a bit better for the `CountVectorizer` doing better  for Bayes and Logit classifiers, and `TfidfVectorizers` for the SVC case.  \n",
    "The number of features decreases rapidly by increasing the min_df, without decreasing considerably the performance of all 3 classifiers. In addition, the SVC computing time  also decreases strongly.  \n",
    "Before conducting a grid search to optimize the parameters and find the best classifier, lets look if using *character or word n-grams* helps to improve the algorithms performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Vocabulary length for ngram_range=(1,3) (min_df=3) -->  7000 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.98 , 0.97\n",
      "Test: 0.96 , 0.95\n",
      "CPU times: user 402 ms, sys: 3.38 ms, total: 406 ms\n",
      "Wall time: 405 ms\n",
      "######### Vocabulary length for ngram_range=(1,4) (min_df=3) -->  8034 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.97 , 0.97\n",
      "Test: 0.94 , 0.94\n",
      "CPU times: user 474 ms, sys: 162 µs, total: 474 ms\n",
      "Wall time: 473 ms\n",
      "######### Vocabulary length for ngram_range=(1,5) (min_df=3) -->  8893 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.97 , 0.96\n",
      "Test: 0.94 , 0.93\n",
      "CPU times: user 550 ms, sys: 3.85 ms, total: 554 ms\n",
      "Wall time: 554 ms\n"
     ]
    }
   ],
   "source": [
    "# tokenize strategy: word n-grams \n",
    "for i in [3,4,5]:\n",
    "    v1 = CountVectorizer(ngram_range=(1,i),min_df=3).fit(X_train[\"text\"])\n",
    "    v2 = TfidfVectorizer(ngram_range=(1,i),min_df=3).fit(X_train[\"text\"])\n",
    "    print(\"######### Vocabulary length for ngram_range=(1,{}) (min_df=3) -->  {} #########\".format(i, len(v1.vocabulary_)))\n",
    "    %time vectorizer_performance(v1,v2,\"Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Vocabulary length for ngram_range=(1,3) (min_df=5) -->  5059 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.97 , 0.97\n",
      "Test: 0.97 , 0.96\n",
      "CPU times: user 1.13 s, sys: 3.81 ms, total: 1.13 s\n",
      "Wall time: 1.13 s\n",
      "######### Vocabulary length for ngram_range=(1,4) (min_df=5) -->  10654 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.98 , 0.97\n",
      "Test: 0.98 , 0.97\n",
      "CPU times: user 1.61 s, sys: 0 ns, total: 1.61 s\n",
      "Wall time: 1.61 s\n",
      "######### Vocabulary length for ngram_range=(1,5) (min_df=5) -->  15569 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.98 , 0.98\n",
      "Test: 0.98 , 0.97\n",
      "CPU times: user 1.74 s, sys: 4 ms, total: 1.74 s\n",
      "Wall time: 1.74 s\n"
     ]
    }
   ],
   "source": [
    "# tokenize strategy: character n-grams within word boundaries\n",
    "for i in [3,4,5]:\n",
    "    v1 = CountVectorizer(analyzer='char_wb',ngram_range=(2,i),min_df=5).fit(X_train[\"text\"])\n",
    "    v2 = TfidfVectorizer(analyzer='char_wb',ngram_range=(2,i),min_df=5).fit(X_train[\"text\"])\n",
    "    print(\"######### Vocabulary length for ngram_range=(1,{}) (min_df=5) -->  {} #########\".format(i, len(v1.vocabulary_)))\n",
    "    %time vectorizer_performance(v1,v2,\"Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using *word n-grams* does not seem to improve significantly the algorithms performance and approximately doubles the computing time. However, the use of **character n-grams within word boundaries** does improve significantly but at the same time increases the Bayes computing time by about three times. This last choice should make the different models  more robust to misspelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding extra features (length, non-alphan.  and numer. charac.):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the rather good performance of some of the previous classifiers it does not seem, at first glance, the necessity of adding extra features (or even optimizing parameters for regularization). However, recall that the previous best classifiers have a rather large number of features and slow computing time, so faster-training models with equally good performance would be much better. \n",
    "\n",
    "Let's add the features disscussed in the text data analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "add_sparse_feat = lambda X_sparse_set, new_feat: hstack( [X_sparse_set, csr_matrix(new_feat).T], 'csr')\n",
    " \n",
    "def new_vectorizer_performance(v1,v2,classif):\n",
    "    auc_train = []\n",
    "    auc_test  = []\n",
    "    trained_clf = []\n",
    "    for vectorizer in [v1,v2]:\n",
    "        #adding new features:\n",
    "        X_train_transf = add_sparse_feat(vectorizer.transform(X_train[\"text\"]),[ X_train[i].values for i in [\"msg_len\",\"non_word_char\",\"num_char\"]])\n",
    "        #X_train_transf = vectorizer.transform(X_train[\"text\"])\n",
    "        clf = model[classif].fit(X_train_transf,y_train)\n",
    "        trained_clf.append(clf)\n",
    "        y_pred_train = clf.predict(X_train_transf)\n",
    "        auc_train.append(roc_auc_score(y_train,y_pred_train) )\n",
    "        # transforming X_test adding new features\n",
    "        X_test_transf = add_sparse_feat(vectorizer.transform(X_test[\"text\"]),[ X_test[i].values for i in [\"msg_len\",\"non_word_char\",\"num_char\"]])            \n",
    "        y_pred = clf.predict(X_test_transf)\n",
    "        auc_test.append(roc_auc_score(y_test,y_pred) )\n",
    "    print(\"*** AUC scores for {} Classifier ***\".format(classif))\n",
    "    print(\"Train: {:0.2f} , {:0.2f}\".format(auc_train[0],auc_train[1]))\n",
    "    print(\"Test: {:0.2f} , {:0.2f}\".format(auc_test[0],auc_test[1]))\n",
    "    return trained_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Vocabulary length for ngram_range=(1,3) (min_df=5) -->  500 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.95 , 0.94\n",
      "Test: 0.95 , 0.92\n",
      "CPU times: user 1.12 s, sys: 0 ns, total: 1.12 s\n",
      "Wall time: 1.12 s\n",
      "######### Vocabulary length for ngram_range=(1,4) (min_df=5) -->  500 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.95 , 0.93\n",
      "Test: 0.94 , 0.92\n",
      "CPU times: user 1.42 s, sys: 0 ns, total: 1.42 s\n",
      "Wall time: 1.42 s\n",
      "######### Vocabulary length for ngram_range=(1,5) (min_df=5) -->  500 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.95 , 0.93\n",
      "Test: 0.94 , 0.92\n",
      "CPU times: user 1.6 s, sys: 8 ms, total: 1.61 s\n",
      "Wall time: 1.61 s\n"
     ]
    }
   ],
   "source": [
    "# tokenize strategy: character n-grams within word boundaries, max number of features = 500\n",
    "for i in [3,4,5]:\n",
    "    v1 = CountVectorizer(analyzer='char_wb',ngram_range=(2,i),min_df=0.01,max_features=500).fit(X_train[\"text\"])\n",
    "    v2 = TfidfVectorizer(analyzer='char_wb',ngram_range=(2,i),min_df=0.01,max_features=500).fit(X_train[\"text\"])\n",
    "    print(\"######### Vocabulary length for ngram_range=(1,{}) (min_df=5) -->  {} #########\".format(i, len(v1.vocabulary_)))\n",
    "    %time new_vectorizer_performance(v1,v2,\"Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding these extra features largely improves the training process for the Bayes Classifier: **The training time is decrease after limiting the number of tokenized features to 500**  \n",
    "Let's find out what are the most important features of the model using n-grams in different ranges: (3,4), (3,5), (3,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### ngram_range=(4,4) - min_df= 10 - vocab.len = 503 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.95 , 0.94\n",
      "Test: 0.95 , 0.92\n",
      "CountVectorizer features with:\n",
      "highest coefficients:['ur ', 'cal', 'call', ' ca', ' to ', 'to ', ' to', 'non_wordchar', 'digit', 'msg_len']\n",
      "smallest coefficients:[' &l', '&lt;', '&lt', '&gt;', '&gt', '#&gt', '#&g', ';#&', 'lt;', 'she']\n",
      "TfidfVectorizer features with:\n",
      "highest coefficients:['ur ', 'cal', 'call', ' ca', ' to ', 'to ', ' to', 'non_wordchar', 'digit', 'msg_len']\n",
      "smallest coefficients:[' &l', '&lt;', '&lt', '&gt;', '&gt', '#&gt', '#&g', ';#&', 'lt;', 'she']\n",
      "######### ngram_range=(4,5) - min_df= 10 - vocab.len = 503 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.94 , 0.94\n",
      "Test: 0.95 , 0.93\n",
      "CountVectorizer features with:\n",
      "highest coefficients:['ur ', 'cal', 'call', ' ca', ' to ', 'to ', ' to', 'non_wordchar', 'digit', 'msg_len']\n",
      "smallest coefficients:[' &l', '#&gt', '#&gt;', '&gt', '&gt;', '&gt; ', '&lt', '&lt;', '&lt;#', ';#&']\n",
      "TfidfVectorizer features with:\n",
      "highest coefficients:['ur ', 'cal', 'call', ' ca', ' to ', 'to ', ' to', 'non_wordchar', 'digit', 'msg_len']\n",
      "smallest coefficients:[' &l', '#&gt', '#&gt;', '&gt', '&gt;', '&gt; ', '&lt', '&lt;', '&lt;#', ';#&']\n",
      "######### ngram_range=(4,6) - min_df= 10 - vocab.len = 503 #########\n",
      "*** AUC scores for Bayes Classifier ***\n",
      "Train: 0.94 , 0.94\n",
      "Test: 0.95 , 0.92\n",
      "CountVectorizer features with:\n",
      "highest coefficients:['ur ', 'cal', 'call', ' ca', ' to ', 'to ', ' to', 'non_wordchar', 'digit', 'msg_len']\n",
      "smallest coefficients:[' &l', ';#&g', ';#&', '&lt;#&', '&lt;', '&lt', '&gt; ', '&gt;', '&gt', ';#&gt']\n",
      "TfidfVectorizer features with:\n",
      "highest coefficients:['ur ', 'cal', 'call', ' ca', ' to ', 'to ', ' to', 'non_wordchar', 'digit', 'msg_len']\n",
      "smallest coefficients:[' &l', ';#&g', ';#&', '&lt;#&', '&lt;', '&lt', '&gt; ', '&gt;', '&gt', ';#&gt']\n"
     ]
    }
   ],
   "source": [
    "# tokenize strategy: character n-grams within word boundaries, max number of features = 500 + 3 extra\n",
    "for i in [4,5,6]:\n",
    "    v1 = CountVectorizer(analyzer='char_wb',ngram_range=(3,i),min_df=0.01,max_features=500).fit(X_train[\"text\"])\n",
    "    v2 = TfidfVectorizer(analyzer='char_wb',ngram_range=(3,i),min_df=0.01,max_features=500).fit(X_train[\"text\"])\n",
    "    print(\"######### ngram_range=(4,{}) - min_df= 10 - vocab.len = 503 #########\".format(i))\n",
    "    clf_v1, clf_v2 = new_vectorizer_performance(v1,v2,\"Bayes\")\n",
    "\n",
    "    for v,clf,name in [(v1,clf_v1,\"CountVectorizer\"),(v2,clf_v2,\"TfidfVectorizer\")]:\n",
    "        vv = v.vocabulary_\n",
    "        for i,j in zip([500,501,502],['msg_len', 'digit', 'non_wordchar']):\n",
    "            vv[j] = i \n",
    "        extended_vv = dict(zip(vv.values(),vv.keys()))\n",
    "        idx_sorted = clf.coef_[0].argsort()\n",
    "        scl= [extended_vv[i] for i in idx_sorted[:10]]\n",
    "        hcl= [extended_vv[i] for i in idx_sorted[-10:]]\n",
    "        print(\"{} features with:\".format(name))\n",
    "        print(\"highest coefficients:{}\".format(hcl))\n",
    "        print(\"smallest coefficients:{}\".format(scl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The last 3 features added are key for the classifiers to distinguish between spam and non-spam messages.\n",
    "The next section will optimize the model parameters and additional hyper-parameters (regularization, vectorizer params, etc)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "Pn19K",
   "launcher_item_id": "y1juS",
   "part_id": "ctlgo"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
